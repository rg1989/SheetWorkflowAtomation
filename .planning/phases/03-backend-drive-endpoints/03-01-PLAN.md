---
phase: 03-backend-drive-endpoints
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/api/drive.py
  - backend/app/main.py
  - backend/app/auth/router.py
autonomous: true

must_haves:
  truths:
    - "POST /api/drive/download accepts file_id and returns file metadata + parsed data preview"
    - "POST /api/sheets/read accepts spreadsheet_id and optional range_name, returns metadata + parsed data"
    - "GET /api/auth/token returns decrypted access token and expiry for Picker authentication"
    - "All endpoints return user-friendly error messages (not raw Google API errors)"
    - "File metadata includes id, name, mimeType, modifiedTime, owner email, and webViewLink"
  artifacts:
    - path: "backend/app/api/drive.py"
      provides: "Drive download and Sheets read REST endpoints with Pydantic models"
      min_lines: 100
    - path: "backend/app/main.py"
      provides: "Drive router registration"
      contains: "drive.router"
    - path: "backend/app/auth/router.py"
      provides: "Token endpoint for Picker auth"
      contains: "/token"
  key_links:
    - from: "backend/app/api/drive.py"
      to: "backend/app/services/drive.py"
      via: "import and call download_drive_file_to_df, get_drive_file_metadata"
      pattern: "from app\\.services\\.drive import"
    - from: "backend/app/api/drive.py"
      to: "backend/app/services/sheets.py"
      via: "import and call read_sheet_to_df"
      pattern: "from app\\.services\\.sheets import"
    - from: "backend/app/api/drive.py"
      to: "backend/app/services/google_auth.py"
      via: "import and call build_drive_service, build_sheets_service"
      pattern: "from app\\.services\\.google_auth import"
    - from: "backend/app/api/drive.py"
      to: "backend/app/auth/deps.py"
      via: "Depends(get_current_user) for authentication"
      pattern: "Depends\\(get_current_user\\)"
    - from: "backend/app/main.py"
      to: "backend/app/api/drive.py"
      via: "app.include_router(drive.router)"
      pattern: "include_router.*drive"
    - from: "backend/app/auth/router.py"
      to: "backend/app/auth/encryption.py"
      via: "decrypt_token for access token"
      pattern: "decrypt_token"
---

<objective>
Create REST API endpoints exposing Phase 2's Drive/Sheets service layer to the frontend.

Purpose: Frontend needs HTTP endpoints to trigger Drive file downloads, Sheets reads, and get access tokens for Google Picker initialization. This is the HTTP layer connecting frontend requests to the existing service layer.

Output: New `backend/app/api/drive.py` with Drive/Sheets endpoints, token endpoint added to auth router, router registered in main.py.
</objective>

<execution_context>
@/Users/rgv250cc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rgv250cc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 2 summaries - needed for service layer API surface
@.planning/phases/02-backend-drive-service/02-01-SUMMARY.md
@.planning/phases/02-backend-drive-service/02-02-SUMMARY.md

# Existing code to reference for patterns
@backend/app/api/files.py
@backend/app/services/drive.py
@backend/app/services/sheets.py
@backend/app/services/google_auth.py
@backend/app/auth/router.py
@backend/app/auth/deps.py
@backend/app/auth/encryption.py
@backend/app/main.py
@backend/app/models/workflow.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Drive and Sheets API endpoints with Pydantic models</name>
  <files>backend/app/api/drive.py, backend/app/main.py</files>
  <action>
Create `backend/app/api/drive.py` with two POST endpoints and Pydantic request/response models.

**Pydantic Models (defined at top of file):**

1. `DownloadRequest(BaseModel)`:
   - `file_id: str` (required, Field description="Google Drive file ID")

2. `SheetsReadRequest(BaseModel)`:
   - `spreadsheet_id: str` (required, Field description="Google Sheets spreadsheet ID")
   - `range_name: Optional[str] = None` (Field description="A1 notation range, e.g. 'Sheet1!A1:D10'")

3. `FileMetadata(BaseModel)`:
   - `id: str`
   - `name: str`
   - `mime_type: str`
   - `modified_time: str`
   - `owner: str`
   - `web_view_link: str`
   - `size: Optional[int] = None`

4. `DriveFileResponse(BaseModel)`:
   - `success: bool`
   - `file_metadata: FileMetadata`
   - `row_count: int`
   - `columns: list[str]`
   - `sample_data: list[dict]` (first 5 rows as dicts)

**Router:** `router = APIRouter()`

**Endpoint 1: POST /download**
- Signature: `async def download_drive_file(request: DownloadRequest, current_user: UserDB = Depends(get_current_user), db: AsyncSession = Depends(get_db))`
- response_model=DriveFileResponse
- Steps:
  1. Build drive_service via `build_drive_service(current_user, db)`
  2. Build sheets_service via `build_sheets_service(current_user, db)`
  3. Get file metadata via `get_drive_file_metadata(drive_service, request.file_id)` - this satisfies SELECT-02
  4. Download and parse via `download_drive_file_to_df(drive_service, request.file_id, mime_type=metadata["mimeType"], sheets_service=sheets_service)`
  5. Convert first 5 rows to serializable format: `df.head(5).to_dict('records')` with NaN-to-None conversion (use `math.isnan()` check, same pattern as `backend/app/api/files.py`)
  6. Extract owner email: `metadata.get("owners", [{}])[0].get("emailAddress", "Unknown")`
  7. Return DriveFileResponse with metadata, row_count, columns, sample_data
- Error handling:
  - Catch `ValueError` -> HTTPException 400 (unsupported file type)
  - HttpError already caught by Phase 2 service layer (raises HTTPException)

**Endpoint 2: POST /read**
- Signature: `async def read_google_sheet(request: SheetsReadRequest, current_user: UserDB = Depends(get_current_user), db: AsyncSession = Depends(get_db))`
- response_model=DriveFileResponse (same response shape)
- Steps:
  1. Build sheets_service via `build_sheets_service(current_user, db)`
  2. Build drive_service via `build_drive_service(current_user, db)`
  3. Get file metadata via `get_drive_file_metadata(drive_service, request.spreadsheet_id)` - for SELECT-02
  4. Read sheet via `read_sheet_to_df(sheets_service, request.spreadsheet_id, range_name=request.range_name or "")`
  5. Same serialization as endpoint 1 (NaN-to-None, sample rows)
  6. Return DriveFileResponse
- Error handling: same pattern as endpoint 1

**Imports:**
```python
import math
import logging
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from app.auth.deps import get_current_user
from app.db.database import get_db
from app.db.models import UserDB
from app.services.google_auth import build_drive_service, build_sheets_service
from app.services.drive import download_drive_file_to_df, get_drive_file_metadata
from app.services.sheets import read_sheet_to_df
```

**Helper function** `_sanitize_sample_rows(df, n=5) -> list[dict]`:
Extract into shared helper since both endpoints use the same NaN-to-None logic:
```python
def _sanitize_sample_rows(df, n=5):
    rows = df.head(n).to_dict('records')
    for row in rows:
        for key, value in row.items():
            if isinstance(value, float) and math.isnan(value):
                row[key] = None
    return rows
```

**Register router in main.py:**
Add `from app.api import drive` to imports alongside existing `from app.api import workflows, runs, files`.
Add `app.include_router(drive.router, prefix="/api/drive", tags=["drive"])` after the existing files router line.

**Follow existing conventions:**
- Module docstring at top
- `logger = logging.getLogger("uvicorn.error")` for consistency
- 4-space indentation
- snake_case functions, PascalCase Pydantic models
- Endpoint docstrings explaining what the endpoint does
  </action>
  <verify>
1. `python -c "from app.api.drive import router; print('Import OK, routes:', [r.path for r in router.routes])"` from backend directory
2. `python -c "from app.api.drive import DownloadRequest, SheetsReadRequest, FileMetadata, DriveFileResponse; print('Models OK')"` from backend directory
3. `python -c "from app.main import app; routes = [r.path for r in app.routes]; assert '/api/drive/download' in routes or any('drive' in str(r.path) for r in app.routes); print('Router registered')"` from backend directory
  </verify>
  <done>
POST /api/drive/download accepts file_id and returns DriveFileResponse with file_metadata (id, name, mime_type, modified_time, owner, web_view_link), row_count, columns, and sample_data. POST /api/drive/read (mounted under /api/drive prefix as /read) accepts spreadsheet_id and optional range_name, returns same response shape. Both use Depends(get_current_user) for auth. Router registered in main.py under /api/drive prefix.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add token endpoint to auth router for Picker authentication</name>
  <files>backend/app/auth/router.py</files>
  <action>
Add a GET /token endpoint to the existing auth router in `backend/app/auth/router.py`.

**Endpoint: GET /token**
- Signature: `async def get_access_token(current_user: UserDB = Depends(get_current_user), db: AsyncSession = Depends(get_db))`
- Purpose: Return the user's current valid Google access token so the frontend can initialize Google Picker.
- Steps:
  1. Check if user has Drive tokens: `if not current_user.google_access_token` -> HTTPException 401 detail="No Google access token. Connect Google Drive first."
  2. Get valid access token via `get_valid_access_token(current_user, db)` from `app.auth.token_refresh` (this handles refresh if expired)
  3. Return `{"access_token": access_token, "expires_at": current_user.token_expiry.isoformat() if current_user.token_expiry else None}`
- Error handling:
  - `get_valid_access_token` already raises HTTPException 401 with "drive_reconnect_required" if refresh fails
  - Catch `ValueError` (user has no Drive connection) -> HTTPException 401 with clear message

**Add import at top of file:** `from app.auth.token_refresh import get_valid_access_token` (token_refresh already imported indirectly, but needs explicit import).

**Note:** Do NOT decrypt the token manually -- use `get_valid_access_token()` which handles both decryption and refresh. This is the correct approach because:
- Token may be expired and need refresh before returning
- `get_valid_access_token` already handles all edge cases (expired, revoked, decryption failure)
- Returns plaintext token ready for Picker use

**Place the new endpoint** after the existing `/drive-status` endpoint and before the `/logout` endpoint for logical grouping.
  </action>
  <verify>
1. `python -c "from app.auth.router import router; paths = [r.path for r in router.routes]; assert '/token' in paths; print('Token endpoint registered:', paths)"` from backend directory
2. Verify the endpoint is accessible at GET /api/auth/token (since auth router has prefix="/auth" and is mounted at prefix="/api")
  </verify>
  <done>
GET /api/auth/token returns current user's valid access token and expiry timestamp. Uses get_valid_access_token() for automatic refresh. Returns 401 if user has no Drive connection or if refresh fails.
  </done>
</task>

</tasks>

<verification>
1. All three endpoints exist and are reachable:
   - POST /api/drive/download (accepts file_id in JSON body)
   - POST /api/drive/read (accepts spreadsheet_id and optional range_name in JSON body)
   - GET /api/auth/token (returns access_token and expires_at)
2. Pydantic models validate request/response schemas correctly
3. All endpoints require authentication via Depends(get_current_user)
4. Error responses use HTTPException with user-friendly messages
5. File metadata includes all SELECT-02 fields: name, owner, modified time, webViewLink
6. NaN values in sample data are converted to None for JSON serialization
7. No new dependencies required (all imports from existing codebase)
</verification>

<success_criteria>
- `python -c "from app.api.drive import router"` succeeds without errors
- `python -c "from app.main import app"` succeeds and includes drive routes
- POST /api/drive/download endpoint accepts DownloadRequest, returns DriveFileResponse
- POST /api/drive/read endpoint accepts SheetsReadRequest, returns DriveFileResponse
- GET /api/auth/token endpoint returns access token with expiry
- All error paths raise HTTPException (not raw exceptions)
</success_criteria>

<output>
After completion, create `.planning/phases/03-backend-drive-endpoints/03-01-SUMMARY.md`
</output>
