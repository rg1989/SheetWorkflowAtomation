---
phase: 06-export-to-drive
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/services/sheets.py
  - backend/app/api/drive.py
autonomous: true

must_haves:
  truths:
    - "User can create a new Google Sheet in Drive containing workflow results"
    - "User can update an existing Google Sheet by overwriting its contents with workflow results"
    - "Download option remains available alongside Drive export (existing endpoint untouched)"
    - "After export, user receives spreadsheet URL to view result in Google Sheets"
    - "Export operations handle rate limits (429) and permission errors (403) gracefully"
  artifacts:
    - path: "backend/app/services/sheets.py"
      provides: "Sheets write operations: create_spreadsheet, update_sheet_values, dataframe_to_sheets_values"
      exports: ["create_spreadsheet", "update_sheet_values", "dataframe_to_sheets_values"]
    - path: "backend/app/api/drive.py"
      provides: "Export REST endpoints: POST /export/create, POST /export/update"
      contains: "ExportCreateRequest"
  key_links:
    - from: "backend/app/api/drive.py"
      to: "backend/app/services/sheets.py"
      via: "import create_spreadsheet, update_sheet_values"
      pattern: "from app\\.services\\.sheets import.*create_spreadsheet"
    - from: "backend/app/services/sheets.py"
      to: "Google Sheets API v4"
      via: "sheets_service.spreadsheets().create() and .values().update()"
      pattern: "spreadsheets\\(\\)\\.(create|values)"
    - from: "backend/app/api/drive.py"
      to: "backend/app/api/runs.py"
      via: "Loads run output_path to read DataFrame for export"
      pattern: "RunDB.*output_path"
---

<objective>
Add Google Sheets write operations (create new spreadsheet, update existing) to the service layer, then expose them as REST endpoints so the frontend can push workflow results to Drive.

Purpose: Completes the Drive roundtrip -- users can now read FROM Drive (Phase 2-3) and write BACK to Drive, eliminating the download/upload cycle for Drive-centric workflows.
Output: Two new service functions in sheets.py + two new API endpoints in drive.py for creating and updating Google Sheets with workflow result DataFrames.
</objective>

<execution_context>
@/Users/rgv250cc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rgv250cc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-export-to-drive/06-RESEARCH.md
@backend/app/services/sheets.py
@backend/app/services/drive.py
@backend/app/api/drive.py
@backend/app/api/runs.py
@backend/app/services/google_auth.py
@backend/app/db/models.py
@backend/app/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Sheets write operations to service layer</name>
  <files>backend/app/services/sheets.py</files>
  <action>
Add three functions to `backend/app/services/sheets.py`:

1. **`dataframe_to_sheets_values(df: pd.DataFrame) -> list[list]`** (sync helper):
   - Convert DataFrame to Google Sheets values format (list of lists).
   - First row = column headers via `df.columns.tolist()`.
   - Data rows via `df.values.tolist()` with NaN values replaced by None (use `pd.isna()` check per cell).
   - This mirrors the existing `_sanitize_sample_rows` pattern in `api/drive.py` but for full DataFrame output.

2. **`create_spreadsheet(sheets_service, title: str, df: pd.DataFrame) -> dict`** (async):
   - Decorate with `@drive_retry` (already imported from drive.py).
   - Create empty spreadsheet via `sheets_service.spreadsheets().create()` with title in properties.
   - Use `fields="spreadsheetId,spreadsheetUrl"` to get the view link back.
   - Then write data via `update_sheet_values()` to populate Sheet1.
   - Wrap `.execute()` calls in `await asyncio.to_thread(lambda: ...)` (same pattern as `read_sheet_to_df`).
   - Catch `HttpError` and delegate to `_handle_drive_error(e, "new_spreadsheet")`.
   - Return dict: `{"spreadsheetId": str, "spreadsheetUrl": str}`.

3. **`update_sheet_values(sheets_service, spreadsheet_id: str, df: pd.DataFrame, range_name: str = "Sheet1!A1") -> dict`** (async):
   - Decorate with `@drive_retry`.
   - Convert DataFrame using `dataframe_to_sheets_values(df)`.
   - Call `sheets_service.spreadsheets().values().update()` with:
     - `spreadsheetId=spreadsheet_id`
     - `range=range_name`
     - `valueInputOption="USER_ENTERED"` (NOT "RAW" -- USER_ENTERED parses dates/numbers correctly)
     - `body={"values": values}`
   - Wrap `.execute()` in `await asyncio.to_thread(...)`.
   - Log updated cell count via `result.get("updatedCells", 0)`.
   - Catch `HttpError` and delegate to `_handle_drive_error(e, spreadsheet_id)`.
   - Return the raw result dict from the API (contains updatedCells, updatedRows, etc.).

Important:
- Reuse existing imports: `drive_retry` and `_handle_drive_error` are already imported from `app.services.drive`.
- Reuse existing `asyncio` import already at top of file.
- Add `import pandas as pd` check -- it's already imported.
- Do NOT clear the sheet before update -- `values().update()` overwrites the specified range completely.
  </action>
  <verify>
Run `python -c "from app.services.sheets import create_spreadsheet, update_sheet_values, dataframe_to_sheets_values; print('imports OK')"` from the backend directory. Also verify `dataframe_to_sheets_values` works: `python -c "import pandas as pd; from app.services.sheets import dataframe_to_sheets_values; df = pd.DataFrame({'A': [1, 2], 'B': ['x', 'y']}); result = dataframe_to_sheets_values(df); assert result == [['A', 'B'], [1, 'x'], [2, 'y']], f'Got {result}'; print('conversion OK')"` from backend directory.
  </verify>
  <done>
sheets.py exports `create_spreadsheet`, `update_sheet_values`, and `dataframe_to_sheets_values`. The helper converts DataFrames to Sheets format with NaN handling. Both async functions use drive_retry decorator and asyncio.to_thread wrapper consistent with existing read operations.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add export REST endpoints to API layer</name>
  <files>backend/app/api/drive.py</files>
  <action>
Extend `backend/app/api/drive.py` with export endpoints:

1. **Add Pydantic request/response models** (below existing models):

   ```python
   class ExportCreateRequest(BaseModel):
       """Request to create new Google Sheet with workflow results."""
       run_id: str = Field(description="Workflow run ID whose output to export")
       title: str = Field(description="Title for the new Google Sheet")

   class ExportUpdateRequest(BaseModel):
       """Request to update existing Google Sheet with workflow results."""
       run_id: str = Field(description="Workflow run ID whose output to export")
       spreadsheet_id: str = Field(description="Target Google Sheet ID to overwrite")

   class ExportResponse(BaseModel):
       """Response from export operation."""
       success: bool
       spreadsheet_id: str
       spreadsheet_url: str
       updated_cells: int
   ```

2. **Add imports** at top of file:
   - `from app.services.sheets import create_spreadsheet, update_sheet_values`
   - `from app.db.models import UserDB, RunDB` (RunDB needs to be added; UserDB already imported)
   - `from app.models.run import RunStatus` (to check run is completed)
   - `from sqlalchemy import select` (for querying RunDB)
   - `import pandas as pd` (for reading output Excel file)

3. **POST /export/create endpoint**:
   - Path: `@router.post("/export/create", response_model=ExportResponse)`
   - Dependencies: `current_user: UserDB = Depends(get_current_user)`, `db: AsyncSession = Depends(get_db)`
   - Implementation:
     a. Query RunDB by `request.run_id` AND `current_user.id` (enforce ownership).
     b. Validate run exists (404 if not) and status is COMPLETED (400 if not).
     c. Validate `run.output_path` exists on disk (404 if file missing).
     d. Read output file: `df = pd.read_excel(run.output_path, engine="openpyxl")`.
     e. Build sheets service: `sheets_service = await build_sheets_service(current_user, db)`.
     f. Call `result = await create_spreadsheet(sheets_service, request.title, df)`.
     g. Return `ExportResponse(success=True, spreadsheet_id=result["spreadsheetId"], spreadsheet_url=result["spreadsheetUrl"], updated_cells=len(df) * len(df.columns))`.
   - Catch `ValueError` -> 401 (Drive not connected). Let HTTPException from service layer pass through.

4. **POST /export/update endpoint**:
   - Path: `@router.post("/export/update", response_model=ExportResponse)`
   - Same dependencies and run validation as create.
   - Implementation:
     a. Same run query and validation (steps a-d from create).
     b. Build sheets service: `sheets_service = await build_sheets_service(current_user, db)`.
     c. Call `result = await update_sheet_values(sheets_service, request.spreadsheet_id, df)`.
     d. Get spreadsheet URL: build drive service, call `get_drive_file_metadata(drive_service, request.spreadsheet_id)`, extract `webViewLink`.
     e. Return `ExportResponse(success=True, spreadsheet_id=request.spreadsheet_id, spreadsheet_url=metadata.get("webViewLink", ""), updated_cells=result.get("updatedCells", 0))`.
   - Catch `ValueError` -> 401. Let HTTPException pass through (covers 403 permission denied on read-only sheets).

Important:
- Do NOT modify existing endpoints or models -- only ADD new ones.
- The existing `/download/{run_id}/download/excel` endpoint in runs.py remains untouched (OUTPUT-03 compliance).
- Error handling for 403 on write-only sheets is handled by `_handle_drive_error` in the service layer -- the endpoint does not need to catch it separately.
- Use `os.path.exists` check on `run.output_path` before attempting to read (already imported in drive.py scope, add `import os` if missing).
  </action>
  <verify>
Run `python -c "from app.api.drive import router; routes = [r.path for r in router.routes]; assert '/export/create' in routes, f'Missing /export/create in {routes}'; assert '/export/update' in routes, f'Missing /export/update in {routes}'; print('endpoints registered:', routes)"` from the backend directory. Also check imports: `python -c "from app.api.drive import ExportCreateRequest, ExportUpdateRequest, ExportResponse; print('models OK')"`.
  </verify>
  <done>
Two new POST endpoints exist: `/api/drive/export/create` (creates new Google Sheet from run output) and `/api/drive/export/update` (overwrites existing Sheet). Both validate run ownership, check completion status, read the output Excel file, and call the sheets service layer. ExportResponse includes spreadsheet_url for the "View in Google Sheets" link. Existing download endpoint in runs.py remains untouched.
  </done>
</task>

</tasks>

<verification>
1. Import check: `cd backend && python -c "from app.services.sheets import create_spreadsheet, update_sheet_values, dataframe_to_sheets_values; from app.api.drive import ExportCreateRequest, ExportUpdateRequest, ExportResponse; print('All imports OK')"`
2. DataFrame conversion test: `cd backend && python -c "
import pandas as pd
import math
from app.services.sheets import dataframe_to_sheets_values
df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Score': [95, None]})
values = dataframe_to_sheets_values(df)
assert values[0] == ['Name', 'Score'], f'Headers wrong: {values[0]}'
assert values[1] == ['Alice', 95], f'Row 1 wrong: {values[1]}'
assert values[2][1] is None, f'NaN not converted: {values[2][1]}'
print('DataFrame conversion: PASS')
"`
3. Endpoint registration: `cd backend && python -c "
from app.api.drive import router
paths = [r.path for r in router.routes]
assert '/export/create' in paths
assert '/export/update' in paths
assert '/download' in paths  # existing endpoint still present
assert '/read' in paths      # existing endpoint still present
print('All endpoints registered:', paths)
"`
4. Existing download endpoint untouched: `cd backend && python -c "from app.api.runs import router; paths = [r.path for r in router.routes]; assert '/{run_id}/download/{file_type}' in paths; print('Download endpoint preserved:', paths)"`
</verification>

<success_criteria>
- sheets.py has three new exports: create_spreadsheet, update_sheet_values, dataframe_to_sheets_values
- drive.py API has two new POST endpoints: /export/create and /export/update
- Both endpoints validate run ownership and completion status before exporting
- ExportResponse includes spreadsheet_url for "View in Google Sheets" link
- All write operations use drive_retry decorator for rate limit handling
- All write operations delegate to _handle_drive_error for 403/404 errors
- Existing /download endpoint in runs.py is completely untouched
- All verification commands pass without errors
</success_criteria>

<output>
After completion, create `.planning/phases/06-export-to-drive/06-01-SUMMARY.md`
</output>
