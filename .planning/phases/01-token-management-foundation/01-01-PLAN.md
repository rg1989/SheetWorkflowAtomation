---
phase: 01-token-management-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/requirements.txt
  - backend/app/db/models.py
  - backend/app/db/database.py
  - backend/app/auth/encryption.py
autonomous: true

must_haves:
  truths:
    - "UserDB model has columns for google_access_token, google_refresh_token, token_expiry, and drive_scopes"
    - "Token encryption module encrypts and decrypts strings using Fernet symmetric encryption"
    - "Existing database tables gain new columns via startup migration without data loss"
    - "cryptography package is listed in requirements.txt"
  artifacts:
    - path: "backend/app/auth/encryption.py"
      provides: "Fernet token encryption/decryption utilities"
      exports: ["encrypt_token", "decrypt_token"]
    - path: "backend/app/db/models.py"
      provides: "Extended UserDB model with token columns"
      contains: "google_access_token"
    - path: "backend/app/db/database.py"
      provides: "Migration logic adding token columns to existing users table"
      contains: "google_access_token"
    - path: "backend/requirements.txt"
      provides: "cryptography dependency"
      contains: "cryptography"
  key_links:
    - from: "backend/app/auth/encryption.py"
      to: "backend/app/auth/config.py"
      via: "reads SESSION_SECRET_KEY or TOKEN_ENCRYPTION_KEY env var for Fernet key derivation"
      pattern: "SESSION_SECRET_KEY|TOKEN_ENCRYPTION_KEY"
    - from: "backend/app/db/database.py"
      to: "backend/app/db/models.py"
      via: "migration adds columns defined in UserDB model"
      pattern: "google_access_token"
---

<objective>
Add token storage columns to the UserDB model, create a Fernet-based encryption module for securing refresh tokens at rest, and extend the database migration to add these columns to existing databases.

Purpose: All subsequent Drive features depend on storing and encrypting OAuth tokens in the database. This plan establishes the data layer foundation.
Output: Extended UserDB model, encryption utilities, updated migration, cryptography dependency.
</objective>

<execution_context>
@/Users/rgv250cc/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rgv250cc/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@backend/app/db/models.py
@backend/app/db/database.py
@backend/app/auth/config.py
@backend/requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add token columns to UserDB and create encryption module</name>
  <files>
    backend/app/db/models.py
    backend/app/auth/encryption.py
    backend/requirements.txt
  </files>
  <action>
1. Add `cryptography>=42.0.0` to `backend/requirements.txt` (after the existing auth section).

2. Extend `UserDB` in `backend/app/db/models.py` with four new columns:
   - `google_access_token = Column(String, nullable=True)` — encrypted access token
   - `google_refresh_token = Column(String, nullable=True)` — encrypted refresh token
   - `token_expiry = Column(DateTime, nullable=True)` — UTC expiry timestamp of access token
   - `drive_scopes = Column(String, nullable=True)` — space-separated list of granted scopes (e.g. "openid email profile https://www.googleapis.com/auth/drive.file https://www.googleapis.com/auth/spreadsheets")

   Add these AFTER the existing `created_at` column. Keep all existing columns unchanged.

3. Create `backend/app/auth/encryption.py` with:
   - A module-level function `_get_fernet_key()` that:
     - Reads `TOKEN_ENCRYPTION_KEY` from env first; if not set, falls back to `SESSION_SECRET_KEY` from `app.auth.config`
     - Uses PBKDF2HMAC (SHA256, 480000 iterations, salt=b"sheet-workflow-token-encryption") to derive a 32-byte key from the secret
     - Returns a `Fernet` instance (cached via module-level `_fernet` variable for reuse)
     - Logs a warning via `logging.getLogger("uvicorn.error")` if falling back to SESSION_SECRET_KEY (since coupling encryption to session key is less ideal)
   - `encrypt_token(plaintext: str) -> str` — encrypts with Fernet, returns base64 string
   - `decrypt_token(ciphertext: str) -> str` — decrypts with Fernet, returns plaintext
   - Both functions handle `None` input gracefully (return `None`)
   - `decrypt_token` catches `InvalidToken` exception and raises `ValueError("Token decryption failed — encryption key may have changed")` with a clear message

   Use `from cryptography.fernet import Fernet, InvalidToken` and `from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC` and `from cryptography.hazmat.primitives import hashes`. Use `import base64` for URL-safe base64 encoding of the derived key.

   Follow existing Python conventions: snake_case, docstrings, 4-space indent.
  </action>
  <verify>
    - `python -c "from app.auth.encryption import encrypt_token, decrypt_token; enc = encrypt_token('test-token'); assert decrypt_token(enc) == 'test-token'; print('OK')"` (run from backend/ with SESSION_SECRET_KEY set)
    - `python -c "from app.db.models import UserDB; assert hasattr(UserDB, 'google_access_token'); assert hasattr(UserDB, 'google_refresh_token'); assert hasattr(UserDB, 'token_expiry'); assert hasattr(UserDB, 'drive_scopes'); print('OK')"` (run from backend/)
    - `grep 'cryptography' backend/requirements.txt` returns a match
  </verify>
  <done>
    - UserDB has google_access_token, google_refresh_token, token_expiry, drive_scopes columns
    - encrypt_token/decrypt_token round-trip works correctly
    - cryptography is in requirements.txt
    - Encryption module uses PBKDF2 key derivation (not raw secret as key)
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend database migration to add token columns to existing tables</name>
  <files>
    backend/app/db/database.py
  </files>
  <action>
Extend the existing `create_tables()` function in `backend/app/db/database.py` to add the four new token columns to existing `users` tables.

The existing pattern (lines 49-62) already handles adding `user_id` to `workflows` and `runs` tables via `PRAGMA table_info` + `ALTER TABLE ADD COLUMN`. Follow the EXACT same pattern for the users table:

In the existing migration block (after the workflows/runs loop), add a new section:
```python
# Migration: add Drive token columns to existing users table (SQLite)
try:
    result = await conn.execute(text("PRAGMA table_info(users)"))
    rows = result.fetchall()
    columns = [row[1] for row in rows]
    for col_name, col_type in [
        ("google_access_token", "VARCHAR"),
        ("google_refresh_token", "VARCHAR"),
        ("token_expiry", "DATETIME"),
        ("drive_scopes", "VARCHAR"),
    ]:
        if col_name not in columns:
            await conn.execute(
                text(f"ALTER TABLE users ADD COLUMN {col_name} {col_type}")
            )
except Exception:
    pass  # Table might not exist yet
```

Place this INSIDE the existing `async with engine.begin() as conn:` block (after the workflows/runs migration loop) to reuse the same connection. Do NOT create a separate `async with engine.begin()` block.

Keep the existing migration logic for workflows/runs tables completely unchanged.
  </action>
  <verify>
    - Start the app (or call create_tables directly) with an existing database that has a users table without token columns. Verify columns are added.
    - `python -c "import asyncio; from app.db.database import create_tables; asyncio.run(create_tables()); print('Migration OK')"` (run from backend/ directory)
    - After migration, verify: `sqlite3 data/workflow.db "PRAGMA table_info(users);"` shows google_access_token, google_refresh_token, token_expiry, drive_scopes columns
  </verify>
  <done>
    - Existing databases gain token columns on startup without data loss
    - Fresh databases get token columns via create_all (from model definition)
    - Migration is idempotent (running twice doesn't error)
    - Existing migration logic for workflows/runs tables still works
  </done>
</task>

</tasks>

<verification>
1. `pip install cryptography` succeeds
2. Encryption round-trip: `encrypt_token("secret") -> decrypt_token(result) == "secret"`
3. UserDB model imports without error and has all four new columns
4. `create_tables()` adds columns to existing database (or creates fresh with columns)
5. Existing app startup still works (no regressions to current login flow)
</verification>

<success_criteria>
- backend/requirements.txt includes cryptography
- backend/app/auth/encryption.py exists with encrypt_token and decrypt_token functions
- backend/app/db/models.py UserDB has google_access_token, google_refresh_token, token_expiry, drive_scopes
- backend/app/db/database.py create_tables() migrates existing users table
- All existing tests/imports continue to work
</success_criteria>

<output>
After completion, create `.planning/phases/01-token-management-foundation/01-01-SUMMARY.md`
</output>
